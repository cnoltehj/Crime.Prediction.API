{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m  \u001b[38;5;66;03m# Import pandas for DataFrame handling\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m  \u001b[38;5;66;03m# Import config module for database connection details\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect_to_database\u001b[39m():\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;66;03m# Get the current script path\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'config'"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd  # Import pandas for DataFrame handling\n",
    "import config  # Import config module for database connection details\n",
    "\n",
    "def connect_to_database():\n",
    "    try:\n",
    "        # Get the current script path\n",
    "        current_path = os.path.dirname(os.path.abspath(__file__))\n",
    "        print(\"Current path:\", current_path)\n",
    "    except NameError:\n",
    "        # Fallback if __file__ is not defined (e.g., in Jupyter)\n",
    "        current_path = os.getcwd()\n",
    "        print(\"Current path:\", current_path)\n",
    "\n",
    "    # Add the parent directory to the system path\n",
    "    sys.path.append(os.path.dirname(current_path))\n",
    "\n",
    "    # Database connection parameters from config\n",
    "    server = config.DefaultConnection['server']\n",
    "    database = config.DefaultConnection['database']\n",
    "    username = config.DefaultConnection['username']\n",
    "    password = config.DefaultConnection['password']\n",
    "\n",
    "    # Establish database connection\n",
    "    cnxn = pyodbc.connect(f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}')\n",
    "    return cnxn\n",
    "\n",
    "def fetch_crime_stats(provincecode, policestation, year=None, quarter=None):\n",
    "    # Connect to the database\n",
    "    cnxn = connect_to_database()\n",
    "    cursor = cnxn.cursor()\n",
    "\n",
    "    try:\n",
    "        # Execute the stored procedure with the parameters\n",
    "        if year:  # Check if the year parameter is not empty\n",
    "            cursor.execute(\"EXEC sp_GetQuartilyCrimeStatsPerQuarter ?, ?, ?, ?\", (provincecode.strip(), policestation.strip(), int(year), int(quarter)))\n",
    "        else:\n",
    "            cursor.execute(\"EXEC sp_GetQuartilyCrimeStatsPerQuarter ?, ?, ?, ?\", (provincecode.strip(), policestation.strip(), None, int(quarter)))\n",
    "\n",
    "        # Fetch the results after executing the stored procedure\n",
    "        rows = cursor.fetchall()\n",
    "\n",
    "        # Fetch the column descriptions (headings)\n",
    "        headings = [column[0] for column in cursor.description]\n",
    "\n",
    "        # Reshape the rows data to match the expected shape\n",
    "        rows = [list(row) for row in rows]\n",
    "\n",
    "        # Create a DataFrame from the fetched rows and headings\n",
    "        df = pd.DataFrame(rows, columns=headings)\n",
    "\n",
    "        # Replace null values with 0's\n",
    "        df.fillna(0, inplace=True)\n",
    "\n",
    "        return df  # Return the DataFrame\n",
    "\n",
    "    except pyodbc.Error as e:\n",
    "        # Print an error message if there's an exception\n",
    "        print(\"Error executing SQL query:\", e)\n",
    "        return None  # Return None if there's an error\n",
    "\n",
    "    finally:\n",
    "        # Close the cursor and connection\n",
    "        cursor.close()\n",
    "        cnxn.close()\n",
    "\n",
    "def fetch_all_provinces():\n",
    "    # Connect to the database\n",
    "    cnxn = connect_to_database()\n",
    "    cursor = cnxn.cursor()\n",
    "\n",
    "    try:\n",
    "            \n",
    "        cursor.execute(\"EXEC sp_GetAllProvinces\")\n",
    "\n",
    "        # Fetch the results after executing the stored procedure\n",
    "        rows = cursor.fetchall()\n",
    "\n",
    "        # Fetch the column descriptions (headings)\n",
    "        headings = [column[0] for column in cursor.description]\n",
    "\n",
    "        # Reshape the rows data to match the expected shape\n",
    "        rows = [list(row) for row in rows]\n",
    "\n",
    "        # Create a DataFrame from the fetched rows and headings\n",
    "        df = pd.DataFrame(rows, columns=headings)\n",
    "\n",
    "        # Replace null values with 0's\n",
    "        df.fillna(0, inplace=True)\n",
    "\n",
    "        return df  # Return the DataFrame\n",
    "\n",
    "    except pyodbc.Error as e:\n",
    "        # Print an error message if there's an exception\n",
    "        print(\"Error executing SQL query:\", e)\n",
    "        return None  # Return None if there's an error\n",
    "\n",
    "    finally:\n",
    "        # Close the cursor and connection\n",
    "        cursor.close()\n",
    "        cnxn.close()\n",
    "\n",
    "def fetch_policestation_per_provinces(provincecode):\n",
    "    # Connect to the database\n",
    "    cnxn = connect_to_database()\n",
    "    cursor = cnxn.cursor()\n",
    "\n",
    "    try:\n",
    "        cursor.execute(\"EXEC sp_GetPoliceStationsPerProvince ?\", (provincecode.strip()))\n",
    "\n",
    "        # Fetch the results after executing the stored procedure\n",
    "        rows = cursor.fetchall()\n",
    "\n",
    "        # Fetch the column descriptions (headings)\n",
    "        headings = [column[0] for column in cursor.description]\n",
    "\n",
    "        # Reshape the rows data to match the expected shape\n",
    "        rows = [list(row) for row in rows]\n",
    "\n",
    "        # Create a DataFrame from the fetched rows and headings\n",
    "        df = pd.DataFrame(rows, columns=headings)\n",
    "\n",
    "        # Replace null values with 0's\n",
    "        df.fillna(0, inplace=True)\n",
    "\n",
    "        return df  # Return the DataFrame\n",
    "\n",
    "    except pyodbc.Error as e:\n",
    "        # Print an error message if there's an exception\n",
    "        print(\"Error executing SQL query:\", e)\n",
    "        return None  # Return None if there's an error\n",
    "\n",
    "    finally:\n",
    "        # Close the cursor and connection\n",
    "        cursor.close()\n",
    "        cnxn.close()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "total = 200\n",
    "print(total)\n",
    "#print('total = {total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample prediction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "import pandas as pd\n",
    "\n",
    "# Function to train and predict per scenario and algorithm\n",
    "def train_and_predict(df, models, params, scenario_func, scenario_name, original_df):\n",
    "    df_encoded = scenario_func(df.copy())\n",
    "    \n",
    "    features = [col for col in df_encoded.columns if col not in ['CrimeCategory', 'ProvinceCode', 'PoliceStationCode', 'Quarter', '2023']]\n",
    "    \n",
    "    # Split the dataset into features and target variable\n",
    "    X = df_encoded[features]\n",
    "    y = df_encoded['TrueValue']  # Adjust this to your target column name\n",
    "\n",
    "    # Split into train (60%), validation (20%), test (20%)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Scaling: Fit only on train data, transform on train, validation, and test\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "\n",
    "    # Define K-Fold cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    realtime_predictions = []\n",
    "    realtime_metrics = []\n",
    "    validation_metrics = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        # Perform Grid Search with cross-validation\n",
    "        grid_search = GridSearchCV(model, params[name], cv=kf, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Predictions on validation set\n",
    "        y_val_pred = best_model.predict(X_val_scaled)\n",
    "\n",
    "        # Predictions on test set\n",
    "        y_test_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "        # Store validation metrics\n",
    "        val_metrics = {\n",
    "            'Algorithm': name,\n",
    "            'Scenario': scenario_name,\n",
    "            'Dataset': 'Validation',\n",
    "            'MAE': mean_absolute_error(y_val, y_val_pred),\n",
    "            'MSE': mean_squared_error(y_val, y_val_pred),\n",
    "            'R²': r2_score(y_val, y_val_pred),\n",
    "            'MAPE': mean_absolute_percentage_error(y_val, y_val_pred)\n",
    "        }\n",
    "        validation_metrics.append(pd.DataFrame([val_metrics]))\n",
    "\n",
    "        # Store test set predictions\n",
    "        scenario_predictions = pd.DataFrame({\n",
    "            'CrimeCategory': original_df.loc[y_test.index, 'CrimeCategory'].values,\n",
    "            'ProvinceCode': original_df.loc[y_test.index, 'ProvinceCode'].values,\n",
    "            'PoliceStationCode': original_df.loc[y_test.index, 'PoliceStationCode'].values,\n",
    "            'Quarter': original_df.loc[y_test.index, 'Quarter'].values,\n",
    "            'Algorithm': [name] * len(y_test),\n",
    "            'Scenario': [scenario_name] * len(y_test),\n",
    "            'Prediction': y_test_pred,\n",
    "            'True_value': y_test\n",
    "        })\n",
    "\n",
    "        # Store test set metrics\n",
    "        test_metrics = {\n",
    "            'Algorithm': name,\n",
    "            'Scenario': scenario_name,\n",
    "            'Dataset': 'Test',\n",
    "            'MAE': mean_absolute_error(y_test, y_test_pred),\n",
    "            'MSE': mean_squared_error(y_test, y_test_pred),\n",
    "            'R²': r2_score(y_test, y_test_pred),\n",
    "            'MAPE': mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "        }\n",
    "        realtime_metrics.append(pd.DataFrame([test_metrics]))\n",
    "\n",
    "        # Append results\n",
    "        realtime_predictions.append(scenario_predictions)\n",
    "\n",
    "    # Concatenate all predictions and metrics after the loop ends\n",
    "    predictions_df = pd.concat(realtime_predictions, axis=0).reset_index(drop=True)\n",
    "    test_metrics_df = pd.concat(realtime_metrics, axis=0).reset_index(drop=True)\n",
    "    val_metrics_df = pd.concat(validation_metrics, axis=0).reset_index(drop=True)\n",
    "\n",
    "    return predictions_df, test_metrics_df, val_metrics_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
